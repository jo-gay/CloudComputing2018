- hosts: all
  tasks:

   - name: Generate hosts file
     lineinfile: dest=/etc/hosts
                 regexp='.*{{ item }}$'
                 line="{{ hostvars[item].ansible_default_ipv4.address }} {{item}}"
                 state=present            
     when: hostvars[item].ansible_default_ipv4.address is defined
     with_items: "{{groups['all']}}"
   
   - name: Set hostname
     hostname: name="{{inventory_hostname}}"
   
   - name: Include variables
     include_vars: setup_var.yml 

   - name: adding paths
     lineinfile: dest="{{rc_file}}" line='export PATH=$PATH:{{spark_home}}/bin/:{{scala_home}}/bin\nexport JAVA_HOME={{java_home}}\nSPARK_HOME={{spark_home}}' insertafter='EOF' regexp='export PATH=\$SPARK_HOME' state=present 

   - name: source bashrc   
     shell: . "{{rc_file}}"

   - name: R repo key
     apt_key: keyserver=keyserver.ubuntu.com id=E084DAB9
 
   - name: R  spark integration
     command: Rscript --slave --no-save --no-restore-history -e "if (! ('{{ item }}' %in% installed.packages()[,'Package'])) { install.packages(pkgs='{{ item }}', repos=c('http://irkernel.github.io/'), type = 'source'); print('Added'); } else { print('Already installed'); }"
     register: r_result
     failed_when: "r_result.rc != 0 or 'had non-zero exit status' in r_result.stderr"
     changed_when: "'Added' in r_result.stdout"
     with_items:
      - rzmq
      - repr
      - evaluate
      - crayon
      - pbdZMQ
      - devtools
      - uuid
      - digest
      - IRkernel
      - IRdisplay

- hosts: sparkmaster
  
  vars_files:
   - setup_var.yml  

  tasks: 
    
   - name: adding paths
     lineinfile: dest={{rc_file}} line='export JUPYTER_CONFIG_DIR={{jupyter_config_dir}}\n export JUPYTER_PATH={{jupyter_path}}\nexport JUPYTER_RUNTIME_DIR={{jupyter_runtime_dir}}' insertafter='EOF' regexp='export JUPYTER_PATH' state=present 

     #lineinfile: dest=/home/ubuntu/.bashrc line='export JUPYTER_CONFIG_DIR=/usr/local/etc/jupyter\n export JUPYTER_PATH=/usr/local/share/jupyter\nexport JUPYTER_RUNTIME_DIR=/usr/local/share/jupyter-runtime' insertafter='EOF' regexp='export PATH=\$SPARK_HOME' state=present 
   
   - name: source bashrc   
     shell: . {{rc_file}}

     #shell: . /home/ubuntu/.bashrc

   - name:  add IRKernel
     command: /usr/bin/Rscript --slave --no-save --no-restore-history -e "devtools::install_github('IRkernel/IRkernel')"

   - name: start IRKernel
     command: /usr/bin/Rscript --slave --no-save --no-restore-history -e "IRkernel::installspec(user = FALSE)"

   - name: start jupyter
     shell: runuser -l ubuntu -c 'jupyter notebook --ip=0.0.0.0 --port=60060 &'
     async: 2592000               # 60*60*24*30 â€“ 1 month
     args:
      executable: /bin/bash 
   
   - name: jupyter server token
     shell: cat /home/ubuntu/.local/share/jupyter/runtime/*.json | grep token
     register: token

   - debug:
      var: token.stdout_lines
   
   - name: disable IPv6
     shell: "{{item}}"
     with_items: 
      - echo "net.ipv6.conf.all.disable_ipv6 = 1\nnet.ipv6.conf.default.disable_ipv6 = 1\nnet.ipv6.conf.lo.disable_ipv6 = 1" >> /etc/sysctl.conf
      - sysctl -p

   - name: start spark master process
     shell: nohup {{spark_home}}/sbin/start-master.sh  &

- hosts: sparkworker
    
  vars_files:
   - setup_var.yml

  tasks:
   - name: disable IPv6
     shell: "{{item}}"
     with_items:
      - echo "net.ipv6.conf.all.disable_ipv6 = 1\nnet.ipv6.conf.default.disable_ipv6 = 1\nnet.ipv6.conf.lo.disable_ipv6 = 1" >> /etc/sysctl.conf
      - sysctl -p
 
   - name: start spark worker process
     shell: nohup {{spark_home}}/sbin/start-slave.sh spark://sparkmaster:7077 &
